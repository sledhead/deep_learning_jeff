{"cells":[{"cell_type":"markdown","metadata":{"id":"KW5FuSyiah4w"},"source":["<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_04_5_rmse_logloss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"zjTpkHllah41"},"source":["# T81-558: Applications of Deep Neural Networks\n","**Module 4: Training for Tabular Data**\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."]},{"cell_type":"markdown","metadata":{"id":"xcv2bXVsah42"},"source":["# Module 4 Material\n","\n","* Part 4.1: Encoding a Feature Vector for Keras Deep Learning [[Video]](https://www.youtube.com/watch?v=Vxz-gfs9nMQ&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_04_1_feature_encode.ipynb)\n","* Part 4.2: Keras Multiclass Classification for Deep Neural Networks with ROC and AUC [[Video]](https://www.youtube.com/watch?v=-f3bg9dLMks&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_04_2_multi_class.ipynb)\n","* Part 4.3: Keras Regression for Deep Neural Networks with RMSE [[Video]](https://www.youtube.com/watch?v=wNhBUC6X5-E&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_04_3_regression.ipynb)\n","* Part 4.4: Backpropagation, Nesterov Momentum, and ADAM Neural Network Training [[Video]](https://www.youtube.com/watch?v=VbDg8aBgpck&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_04_4_backprop.ipynb)\n","* **Part 4.5: Neural Network RMSE and Log Loss Error Calculation from Scratch** [[Video]](https://www.youtube.com/watch?v=wmQX1t2PHJc&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_04_5_rmse_logloss.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"HG_Mgbwrah43"},"source":["# Google CoLab Instructions\n","\n","The following code ensures that Google CoLab is running the correct version of TensorFlow."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"uYzjUOSYah45","outputId":"57f95ba6-41e6-484e-8fff-d16a9c3640ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683349028235,"user_tz":360,"elapsed":16,"user":{"displayName":"snow Burnham","userId":"09431230568873570315"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Note: using Google CoLab\n"]}],"source":["try:\n","    %tensorflow_version 2.x\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False"]},{"cell_type":"markdown","metadata":{"id":"k9RU3onuah48"},"source":["# Part 4.5: Error Calculation from Scratch\n","\n","We will now look at how to calculate RMSE and logloss by hand.  RMSE is typically used for regression. We begin by calculating RMSE with libraries."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"uRR4c9i9ah48","outputId":"75b968db-5c3a-4f3d-e3f2-410ccdff7491","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683349042880,"user_tz":360,"elapsed":1926,"user":{"displayName":"snow Burnham","userId":"09431230568873570315"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Score (MSE): 0.14200000000000007\n","Score (RMSE): 0.37682887362833556\n"]}],"source":["from sklearn import metrics\n","import numpy as np\n","\n","predicted = [1.1,1.9,3.4,4.2,4.3]\n","expected = [1,2,3,4,5]\n","\n","score_mse = metrics.mean_squared_error(predicted,expected)\n","score_rmse = np.sqrt(score_mse)\n","print(\"Score (MSE): {}\".format(score_mse))\n","print(\"Score (RMSE): {}\".format(score_rmse))\n"]},{"cell_type":"markdown","metadata":{"id":"OMBMYI9yah49"},"source":["We can also calculate without libraries."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"XxwM6Ccbah4-","outputId":"1a84de37-6634-466e-9574-f1160eaa2a34","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683349051116,"user_tz":360,"elapsed":184,"user":{"displayName":"snow Burnham","userId":"09431230568873570315"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Score (MSE): 0.14200000000000007\n","Score (RMSE): 0.37682887362833556\n"]}],"source":["score_mse = ((predicted[0]-expected[0])**2 + (predicted[1]-expected[1])**2 \n","+ (predicted[2]-expected[2])**2 + (predicted[3]-expected[3])**2\n","+ (predicted[4]-expected[4])**2)/len(predicted)\n","score_rmse = np.sqrt(score_mse)\n","    \n","print(\"Score (MSE): {}\".format(score_mse))\n","print(\"Score (RMSE): {}\".format(score_rmse))"]},{"cell_type":"markdown","metadata":{"id":"tI7O6rFQah4-"},"source":["## Classification\n","\n","We will now look at how to calculate a logloss by hand. For this, we look at a binary prediction. The predicted is some number between 0-1 that indicates the probability true (1). The expected is always 0 or 1. Therefore, a prediction of 1.0 is completely correct if the expected is 1 and completely wrong if the expected is 0."]},{"cell_type":"code","execution_count":4,"metadata":{"scrolled":true,"id":"8Wt0T9Hdah4_","outputId":"d92d0c9d-514c-4d90-ab6b-b847a513dcb0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683349072630,"user_tz":360,"elapsed":179,"user":{"displayName":"snow Burnham","userId":"09431230568873570315"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0.06678801305495843\n"]}],"source":["from sklearn import metrics\n","\n","expected = [1,1,0,0,0]\n","predicted = [0.9,0.99,0.1,0.05,0.06]\n","\n","print(metrics.log_loss(expected,predicted))"]},{"cell_type":"markdown","metadata":{"id":"SZFDLJ8Eah5A"},"source":["Now we attempt to calculate the same logloss manually."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"r3NBvV6Gah5A","outputId":"08f0482b-b6eb-4b70-c7a0-875c2a0c0841","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683349077118,"user_tz":360,"elapsed":192,"user":{"displayName":"snow Burnham","userId":"09431230568873570315"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Score Logloss 0.06678801305495843\n"]}],"source":["import numpy as np\n","\n","score_logloss = (np.log(1.0-np.abs(expected[0]-predicted[0]))+\\\n","np.log(1.0-np.abs(expected[1]-predicted[1]))+\\\n","np.log(1.0-np.abs(expected[2]-predicted[2]))+\\\n","np.log(1.0-np.abs(expected[3]-predicted[3]))+\\\n","np.log(1.0-np.abs(expected[4]-predicted[4])))\\\n","*(-1/len(predicted))\n","\n","print(f'Score Logloss {score_logloss}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCOj52OAah5A"},"outputs":[],"source":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3.9 (tensorflow)","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[{"file_id":"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_04_5_rmse_logloss.ipynb","timestamp":1683348928109}]}},"nbformat":4,"nbformat_minor":0}